{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0JlIaOimWoflBrQCiuR/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saisathwika-08/Explainable-AI/blob/main/Lab_Assignment_2_Explainabke_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m_-TGIQ7437",
        "outputId": "6d32058d-e46a-480e-a5cb-0d794640318d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 70000\n",
            "Reduced rows: 500\n",
            "=== Classification Metrics ===\n",
            "Accuracy : 0.9061\n",
            "Precision: 0.9004\n",
            "Recall   : 0.9061\n",
            "F1-score : 0.8874\n",
            "ROC AUC  : 0.8545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|===================| 196/200 [00:12<00:00]       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved SHAP summary plot to: ./shap_summary_fast.png\n",
            "\n",
            "=== Top 5 Features by SHAP Importance ===\n",
            "Year               0.009213\n",
            "Height             0.007832\n",
            "Weight             0.007613\n",
            "Sport_Hockey       0.007284\n",
            "Sport_Athletics    0.006516\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# Olympics Medal Prediction + SHAP (Safe Version)\n",
        "# ==============================================\n",
        "# - 80/20 split\n",
        "# - RandomForestClassifier\n",
        "# - Metrics: Accuracy, Precision, Recall, F1, ROC-AUC\n",
        "# - SHAP: summary plot only (50 samples, fast)\n",
        "# ==============================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "# Paths\n",
        "\n",
        "CSV_PATH = \"/content/dataset_olympics.csv\"\n",
        "OUTPUT_DIR = \".\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load and preprocess\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Keep only 500 random rows (or less if dataset is smaller)\n",
        "if len(df) > 500:\n",
        "    df_small = df.sample(n=500, random_state=42)\n",
        "else:\n",
        "    df_small = df.copy()\n",
        "\n",
        "# Save reduced dataset\n",
        "df_small.to_csv(\"dataset_olympics_reduced.csv\", index=False)\n",
        "\n",
        "print(\"Original rows:\", len(df))\n",
        "print(\"Reduced rows:\", len(df_small))\n",
        "\n",
        "df = df.drop(columns=[c for c in [\"ID\", \"Name\"] if c in df.columns])\n",
        "\n",
        "# Target: Medal (fill NaN as \"No Medal\")\n",
        "df[\"Medal\"] = df[\"Medal\"].fillna(\"No Medal\")\n",
        "X = df.drop(columns=[\"Medal\"])\n",
        "y = df[\"Medal\"]\n",
        "\n",
        "# Split categorical/numeric\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_cols),\n",
        "])\n",
        "\n",
        "\n",
        "# Train/test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Model\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", rf)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Metrics\n",
        "\n",
        "y_pred = pipe.predict(X_test)\n",
        "y_proba = pipe.predict_proba(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "rec  = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "f1   = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
        "roc  = roc_auc_score(y_test, y_proba, multi_class=\"ovr\", average=\"macro\")\n",
        "\n",
        "print(\"=== Classification Metrics ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "print(f\"ROC AUC  : {roc:.4f}\")\n",
        "\n",
        "\n",
        "# Feature names\n",
        "\n",
        "def get_feature_names(ct, features):\n",
        "    names = []\n",
        "    for name, trans, cols in ct.transformers_:\n",
        "        if hasattr(trans, \"get_feature_names_out\"):\n",
        "            out = trans.get_feature_names_out(cols)\n",
        "        elif isinstance(trans, Pipeline):\n",
        "            last = trans.steps[-1][1]\n",
        "            if hasattr(last, \"get_feature_names_out\"):\n",
        "                out = last.get_feature_names_out(cols)\n",
        "            else:\n",
        "                out = cols\n",
        "        else:\n",
        "            out = cols\n",
        "        names.extend([str(x) for x in out])\n",
        "    return names\n",
        "\n",
        "feature_names = get_feature_names(pipe.named_steps[\"preprocess\"], X.columns)\n",
        "\n",
        "# SHAP (tiny sample, 50 rows)\n",
        "\n",
        "X_test_trans = pipe.named_steps[\"preprocess\"].transform(X_test)\n",
        "try:\n",
        "    X_test_np = X_test_trans.toarray()\n",
        "except:\n",
        "    X_test_np = np.asarray(X_test_trans)\n",
        "\n",
        "X_shap = X_test_np[:50]  # only 50 rows â†’ very fast\n",
        "explainer = shap.Explainer(rf, X_shap)\n",
        "shap_values = explainer(X_shap)\n",
        "\n",
        "# Save summary plot\n",
        "summary_path = os.path.join(OUTPUT_DIR, \"shap_summary_fast.png\")\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values, features=X_shap, feature_names=feature_names, show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(summary_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\nSaved SHAP summary plot to: {summary_path}\")\n",
        "\n",
        "# Top 5 SHAP features\n",
        "\n",
        "abs_mean_shap = np.abs(shap_values.values).mean(axis=0).mean(axis=1)\n",
        "shap_importance = pd.Series(abs_mean_shap, index=feature_names).sort_values(ascending=False)\n",
        "print(\"\\n=== Top 5 Features by SHAP Importance ===\")\n",
        "print(shap_importance.head(5))"
      ]
    }
  ]
}